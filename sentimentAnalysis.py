import warnings

# Chá»‰ ignore Ä‘Ãºng warning cá»§a Keras vá» cáº¥u trÃºc inputs
warnings.filterwarnings(
    "ignore",
    message="The structure of `inputs` doesn't match the expected structure.",
    category=UserWarning,
)
import pandas as pd
import streamlit as st
import numpy as np
import torch
from PIL import Image

from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.sequence import pad_sequences
from transformers import AutoModel, AutoTokenizer

from streamlit_option_menu import option_menu
from cleandata import Text_PreProcessing_util
# Import thÃªm cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t cho code chuyÃªn Ä‘á»
import tensorflow as tf
from pyvi import ViTokenizer
import pickle


# Load model vÃ  tokenizer cho chuyÃªn Ä‘á»

def load_model_and_tokenizer():
    model = load_model('model/model_bilstm_cnn.keras')
    with open("model/tokenizer_data (100).pkl", "rb") as input_file:
        tokenizer = pickle.load(input_file)
    return model, tokenizer

# Load model vÃ  tokenizer
my_model, my_tokenizer = load_model_and_tokenizer()

# CÃ¡c hÃ m cho chuyÃªn Ä‘á»
def preprocess_raw_input(raw_input, tokenizer):
    input_text_pre = list(tf.keras.preprocessing.text.text_to_word_sequence(raw_input))
    input_text_pre = " ".join(input_text_pre)
    input_text_pre_accent = ViTokenizer.tokenize(input_text_pre)
    tokenized_data_text = tokenizer.texts_to_sequences([input_text_pre_accent])
    vec_data = pad_sequences(tokenized_data_text, padding='post', maxlen=100)
    return vec_data

def inference_model(input_feature, model):
    output = model(input_feature).numpy()[0]
    result = output.argmax()
    conf = float(output.max())
    label_dict = {'TiÃªu cá»±c': 0, 'TÃ­ch cá»±c': 1, 'Trung láº­p': 2}
    label = list(label_dict.keys())
    return label[int(result)], conf

def prediction(raw_input, tokenizer, model):
    input_model = preprocess_raw_input(raw_input, tokenizer)
    result, conf = inference_model(input_model, model)
    return result, conf


# Giao diá»‡n Streamlit
st.set_page_config(
    page_title="Xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn",
    page_icon="ğŸ˜Š",
    layout="wide",
)

st.markdown(
    """
    <style>
    .footer {
        position: fixed;
        left: 0;
        bottom: 0;
        width: 100%;
        color: red;
        text-align: center;
    }

    </style>
    <div class="footer">
        <p>Website Ä‘Æ°á»£c táº¡o bá»Ÿi LÃª Cáº©m Báº±ng</p>
    </div>
    """,
    unsafe_allow_html=True
)

# HÃ m Ä‘á»ƒ hiá»ƒn thá»‹ á»©ng dá»¥ng Sentiment Analysis
def sentiment_analysis_app():
    st.title("PhÃ¢n tÃ­ch cáº£m xÃºc cá»§a ngÆ°á»i mua hÃ ng ğŸ˜ŠğŸ¤”ğŸ˜¢")
    # Add images using HTML and CSS
    st.markdown("""
        <style>
            .image {
                width: 24px;
                height: 24px;
                margin-right: 10px;
            }
        </style>
    """, unsafe_allow_html=True)

    decor = Image.open("decoration.png")
    st.image(decor)

    # Nháº­p vÄƒn báº£n Ä‘áº§u vÃ o
    user_input = st.text_input("Nháº­p vÄƒn báº£n", placeholder="Nháº­p vÄƒn báº£n táº¡i Ä‘Ã¢y...")
    if st.button("PhÃ¢n tÃ­ch"):
        if user_input:
            try:
                # Tiá»n xá»­ lÃ½ vÄƒn báº£n Ä‘áº§u vÃ o
                processed_input = Text_PreProcessing_util([user_input])
                # Dá»± Ä‘oÃ¡n cáº£m xÃºc - Sá»¬ Dá»¤NG CODE CHUYÃŠN Äá»€
                result, conf = prediction(processed_input[0], my_tokenizer, my_model)
                if result == "TÃ­ch cá»±c":
                    st.success(f"Dá»± Ä‘oÃ¡n cáº£m xÃºc: **TÃ­ch cá»±c**")
                elif result == "TiÃªu cá»±c":
                    st.error(f"Dá»± Ä‘oÃ¡n cáº£m xÃºc: **TiÃªu cá»±c**")
                else:
                    st.info(f"Dá»± Ä‘oÃ¡n cáº£m xÃºc: **Trung láº­p**")

            except Exception as e:
                st.error(f"Error: {e}")
        else:
            st.warning("Vui lÃ²ng nháº­p vÄƒn báº£n!")


# HÃ m Ä‘á»ƒ hiá»ƒn thá»‹ á»©ng dá»¥ng Recommendation
def recommendation_app():
    st.title("Khuyáº¿n nghá»‹ Mua hÃ ng Dá»±a trÃªn Ä‘Ã¡nh giÃ¡ Cáº£m xÃºc")


    # File uploader
    uploaded_file = st.file_uploader("Duyá»‡t táº­p dá»¯ liá»‡u", type=["csv", "txt"], label_visibility="visible")

    if uploaded_file is not None:
        file_name = uploaded_file.name
        st.write(f"Tá»‡p Ä‘Ã£ Ä‘Æ°á»£c táº£i lÃªn: {file_name}")

        sentences=[]
        # Read file into a pandas dataframe if it's a CSV
        if file_name.endswith(".csv"):
            df = pd.read_csv(uploaded_file)
            st.write("CÃ¡c hÃ ng Ä‘áº§u tiÃªn cá»§a tá»‡p:")
            st.write(df.head())  # Display first few rows of the uploaded CSV

            # Get list of sentences (assuming one column of text)
            if 'text' in df.columns:
                sentences = df['text'].tolist()
            else:
                st.error("KhÃ´ng tÃ¬m tháº¥y cá»™t 'text' trong tá»‡p CSV.")

        # Read content if it's a TXT file
        elif file_name.endswith(".txt"):
            content = uploaded_file.getvalue().decode("utf-8")
            sentences = content.split("\n")
            st.text(content)  # Display content of the uploaded text file
        else:
            st.error("Loáº¡i tá»‡p khÃ´ng Ä‘Æ°á»£c há»— trá»£. Vui lÃ²ng táº£i lÃªn tá»‡p CSV hoáº·c TXT.")

        if 'sentences' in locals() and sentences:
            st.write("CÃ¡c cÃ¢u trong tá»‡p:")

            with st.spinner("Äang xá»­ lÃ½... Vui lÃ²ng chá» trong khi chÃºng tÃ´i phÃ¢n tÃ­ch cÃ¡c cÃ¢u"):
                results = []

                positive_count = 0
                negative_count = 0
                neutral_count = 0

                for i, sentence in enumerate(sentences):
                    # Tiá»n xá»­ lÃ½ vÄƒn báº£n
                    processed_input = Text_PreProcessing_util([sentence])[0]
                    # Dá»± Ä‘oÃ¡n cáº£m xÃºc - Sá»¬ Dá»¤NG CODE CHUYÃŠN Äá»€
                    result, conf = prediction(processed_input, my_tokenizer, my_model)
                    results.append({"CÃ¢u": sentence, "Cáº£m xÃºc": result})

                    if result == "TÃ­ch cá»±c":
                        positive_count += 1
                    elif result == "TiÃªu cá»±c":
                        negative_count += 1
                    else:
                        neutral_count += 1

                # Chuyá»ƒn danh sÃ¡ch káº¿t quáº£ thÃ nh DataFrame
                results_df = pd.DataFrame(results)

                # TÃ­nh tá»· lá»‡ pháº§n trÄƒm
                total_count = len(sentences)
                positive_percentage = (positive_count / total_count) * 100
                negative_percentage = (negative_count / total_count) * 100
                neutral_percentage = (neutral_count / total_count) * 100

                # Hiá»ƒn thá»‹ káº¿t quáº£
                st.write("Káº¿t quáº£:")
                st.dataframe(results_df)
                st.success("ÄÃ£ hoÃ n táº¥t xá»­ lÃ½ táº¥t cáº£ cÃ¢u!")

                # Hiá»ƒn thá»‹ tá»· lá»‡ pháº§n trÄƒm cáº£m xÃºc tÃ­ch cá»±c vÃ  tiÃªu cá»±c
                st.write(f"Cáº£m xÃºc TÃ­ch cá»±c: {positive_percentage:.2f}%")
                st.write(f"Cáº£m xÃºc TiÃªu cá»±c: {negative_percentage:.2f}%")
                st.write(f"Cáº£m xÃºc Trung láº­p: {neutral_percentage:.2f}%")

                 # Táº¡o dictionary Ä‘á»ƒ so sÃ¡nh tá»· lá»‡ pháº§n trÄƒm
                sentiment_percentages = {
                    "TÃ­ch cá»±c": positive_percentage,
                    "TiÃªu cá»±c": negative_percentage,
                    "Trung láº­p": neutral_percentage
                 }

                # TÃ¬m cáº£m xÃºc cÃ³ tá»· lá»‡ pháº§n trÄƒm cao nháº¥t
                max_sentiment = max(sentiment_percentages, key=sentiment_percentages.get)
                max_percentage = sentiment_percentages[max_sentiment]


                # Quyáº¿t Ä‘á»‹nh cÃ³ nÃªn mua hay khÃ´ng
                if max_sentiment == "TÃ­ch cá»±c":
                    st.success(f"Khuyáº¿n nghá»‹: **NÃªn mua**, báº¡n nÃªn mua sáº£n pháº©m nÃ y.")
                elif max_sentiment == "TiÃªu cá»±c":
                    st.error(f"Khuyáº¿n nghá»‹: **KhÃ´ng nÃªn mua**, báº¡n khÃ´ng nÃªn mua sáº£n pháº©m nÃ y.")
                else:
                    st.info(f"Äá» xuáº¥t: **HÃ£y cÃ¢n nháº¯c**, báº¡n nÃªn cÃ¢n nháº¯c trÆ°á»›c khi mua sáº£n pháº©m nÃ y.")

        else:
            st.warning("KhÃ´ng tÃ¬m tháº¥y cÃ¢u trong tá»‡p Ä‘Ã£ táº£i lÃªn.")


selected = option_menu(
    menu_title=None, #required
    options=["Trang chá»§", "PhÃ¢n tÃ­ch cáº£m xÃºc", "Khuyáº¿n nghá»‹ Mua hÃ ng"], #required
    icons=["house", "emoji-smile", "archive"], #optional
    menu_icon="cast", #optional
    default_index=0, #optional
    orientation="horizontal",
    styles={
        "container": {"padding": "1!important"},
        "icon": {"color": "orange", "font-size": "20px"},
        "nav-link": {
            "font-size": "20px",
            "text-align": "left",
            "margin": "0px",
            "--hover-color": "#eee",
            "font-weight": "normal"
        },
        "nav-link-selected": {"background-color": "green","font-weight": "normal"},
    },
)
hide_st_style = """
<style>
#MainMenu {visibility: hidden;}
footer {visibility: hidden;}
header {visibility: hidden;}

</style>
"""

st.markdown(hide_st_style, unsafe_allow_html=True)
def home():
    st.title("Xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn")
    st.title("XÃ¢y dá»±ng mÃ´ hÃ¬nh phÃ¢n tÃ­ch cáº£m tÃ­nh cá»§a khÃ¡ch hÃ ng trÃªn ná»n táº£ng thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­ Shopee")

if selected == "PhÃ¢n tÃ­ch cáº£m xÃºc":
    sentiment_analysis_app()
elif selected == "Khuyáº¿n nghá»‹ Mua hÃ ng":
    recommendation_app()
elif selected == "Trang chá»§":
    home()